{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQFnIn9sn0ySv4JbdXuq1U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wmalevich/ds_course/blob/main/painting_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cllCVnPLkOqW",
        "outputId": "382161ca-a6bf-497c-ef63-f65f05903fbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/content/yolov5\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"../datasets/\", exist_ok=True)\n",
        "%cd ../datasets/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubUfrep5koPA",
        "outputId": "2517a261-888d-40bd-a25e-82d07b482e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"X4QLc88Uv2q1SRGbaQ31\")\n",
        "project = rf.workspace(\"imgclassifier\").project(\"imgclass\")\n",
        "version = project.version(6)\n",
        "dataset = version.download(\"folder\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7zTiicvla5w",
        "outputId": "a51a8068-6fb1-4b37-b4eb-ae2969f65414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.26)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.50.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = dataset.location.split(os.sep)[-1]\n",
        "os.environ[\"DATASET_NAME\"] = dataset_name"
      ],
      "metadata": {
        "id": "nzh-QVzOlgbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../yolov5\n",
        "!python classify/train.py --model yolov5n-cls.pt --data $DATASET_NAME --epochs 30 --img 640 --pretrained weights/yolov5n-cls.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UE8_DFal0-m",
        "outputId": "fa58e1b7-3d9c-4797-9e45-cd827c4f2ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "2024-03-25 16:36:04.808359: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-25 16:36:04.808490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-25 16:36:04.866174: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5n-cls.pt, data=imgclass-6, epochs=30, batch_size=64, imgsz=640, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=weights/yolov5n-cls.pt, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-295-gac6c4383 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=640, width=640, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), Normalize(p=1.0, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n-cls.pt to yolov5n-cls.pt...\n",
            "100% 4.87M/4.87M [00:00<00:00, 92.8MB/s]\n",
            "\n",
            "Model summary: 149 layers, 1214562 parameters, 1214562 gradients, 3.0 GFLOPs\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 32 weight(decay=0.0), 33 weight(decay=5e-05), 33 bias\n",
            "Image sizes 640 train, 640 test\n",
            "Using 1 dataloader workers\n",
            "Logging results to \u001b[1mruns/train-cls/exp\u001b[0m\n",
            "Starting yolov5n-cls.pt training on imgclass-6 dataset with 2 classes for 30 epochs...\n",
            "\n",
            "     Epoch   GPU_mem  train_loss   test_loss    top1_acc    top5_acc\n",
            "      1/30        0G       0.731        0.69         0.6           1: 100% 2/2 [01:18<00:00, 39.22s/it]\n",
            "      2/30        0G       0.568       0.685         0.6           1: 100% 2/2 [01:13<00:00, 36.85s/it]\n",
            "      3/30        0G       0.736       0.681         0.6           1: 100% 2/2 [01:10<00:00, 35.37s/it]\n",
            "      4/30        0G       0.577       0.678         0.6           1: 100% 2/2 [01:15<00:00, 37.75s/it]\n",
            "      5/30        0G       0.517       0.677         0.6           1: 100% 2/2 [01:07<00:00, 33.81s/it]\n",
            "      6/30        0G       0.535       0.677         0.6           1: 100% 2/2 [01:03<00:00, 31.96s/it]\n",
            "      7/30        0G       0.473       0.678         0.6           1: 100% 2/2 [01:04<00:00, 32.34s/it]\n",
            "      8/30        0G       0.525       0.679         0.6           1: 100% 2/2 [01:07<00:00, 33.58s/it]\n",
            "      9/30        0G       0.506       0.681         0.6           1: 100% 2/2 [01:05<00:00, 32.74s/it]\n",
            "     10/30        0G       0.457       0.685         0.6           1: 100% 2/2 [01:00<00:00, 30.35s/it]\n",
            "     11/30        0G        0.39       0.692         0.6           1: 100% 2/2 [01:05<00:00, 32.64s/it]\n",
            "     12/30        0G       0.427       0.703         0.6           1: 100% 2/2 [01:01<00:00, 30.89s/it]\n",
            "     13/30        0G       0.403       0.722         0.6           1: 100% 2/2 [01:08<00:00, 34.02s/it]\n",
            "     14/30        0G       0.463       0.735         0.6           1: 100% 2/2 [01:03<00:00, 31.90s/it]\n",
            "     15/30        0G       0.395       0.758         0.6           1: 100% 2/2 [01:03<00:00, 31.68s/it]\n",
            "     16/30        0G       0.396       0.772         0.6           1: 100% 2/2 [01:05<00:00, 32.89s/it]\n",
            "     17/30        0G       0.396       0.778         0.6           1: 100% 2/2 [01:00<00:00, 30.50s/it]\n",
            "     18/30        0G       0.358       0.794         0.6           1: 100% 2/2 [01:02<00:00, 31.42s/it]\n",
            "     19/30        0G       0.414       0.805         0.6           1: 100% 2/2 [01:02<00:00, 31.06s/it]\n",
            "     20/30        0G       0.364       0.816         0.6           1: 100% 2/2 [01:03<00:00, 31.62s/it]\n",
            "     21/30        0G       0.383       0.813         0.6           1: 100% 2/2 [01:05<00:00, 32.89s/it]\n",
            "     22/30        0G       0.376       0.819         0.6           1: 100% 2/2 [01:05<00:00, 32.86s/it]\n",
            "     23/30        0G       0.377       0.842         0.6           1: 100% 2/2 [01:07<00:00, 33.56s/it]\n",
            "     24/30        0G       0.396       0.869         0.6           1: 100% 2/2 [01:07<00:00, 33.58s/it]\n",
            "     25/30        0G       0.352       0.899         0.6           1: 100% 2/2 [01:02<00:00, 31.49s/it]\n",
            "     26/30        0G       0.347       0.915         0.6           1: 100% 2/2 [01:02<00:00, 31.49s/it]\n",
            "     27/30        0G       0.315       0.927         0.6           1: 100% 2/2 [01:01<00:00, 30.84s/it]\n",
            "     28/30        0G       0.308       0.938         0.6           1: 100% 2/2 [01:02<00:00, 31.47s/it]\n",
            "     29/30        0G       0.386       0.948         0.6           1: 100% 2/2 [01:02<00:00, 31.11s/it]\n",
            "     30/30        0G       0.326       0.955         0.6           1: 100% 2/2 [01:05<00:00, 33.00s/it]\n",
            "\n",
            "Training complete (0.549 hours)\n",
            "Results saved to \u001b[1mruns/train-cls/exp\u001b[0m\n",
            "Predict:         python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source im.jpg\n",
            "Validate:        python classify/val.py --weights runs/train-cls/exp/weights/best.pt --data /content/datasets/imgclass-6\n",
            "Export:          python export.py --weights runs/train-cls/exp/weights/best.pt --include onnx\n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp/weights/best.pt')\n",
            "Visualize:       https://netron.app\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/val.py --weights runs/train-cls/exp/weights/best.pt --data ../datasets/$DATASET_NAME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwRtJyAumOFx",
        "outputId": "e30e9fe2-1cd9-4d96-b19c-8a8ffe9fdb9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=../datasets/imgclass-6, weights=['runs/train-cls/exp/weights/best.pt'], batch_size=128, imgsz=224, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 ðŸš€ v7.0-295-gac6c4383 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 117 layers, 1211026 parameters, 0 gradients, 2.9 GFLOPs\n",
            "testing: 100% 1/1 [00:00<00:00,  3.86it/s]\n",
            "                   Class      Images    top1_acc    top5_acc\n",
            "                     all           5         0.6           1\n",
            "                   Manet           2           0           1\n",
            "                   Monet           3           1           1\n",
            "Speed: 0.0ms pre-process, 29.4ms inference, 0.1ms post-process per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/val-cls/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source /content/test_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTqPpf6Gl_xS",
        "outputId": "bddb00a4-0be1-40cd-bedd-43b6b975f1ce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mclassify/predict: \u001b[0mweights=['runs/train-cls/exp/weights/best.pt'], source=/content/test_images, data=data/coco128.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs/predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-295-gac6c4383 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 117 layers, 1211026 parameters, 0 gradients, 2.9 GFLOPs\n",
            "image 1/3 /content/test_images/test_image0.jpg: 224x224 Monet 0.88, Manet 0.12, 16.5ms\n",
            "image 2/3 /content/test_images/test_image1.jpg: 224x224 Monet 0.86, Manet 0.14, 12.3ms\n",
            "image 3/3 /content/test_images/test_image2.jpg: 224x224 Monet 0.86, Manet 0.14, 13.6ms\n",
            "Speed: 0.1ms pre-process, 14.1ms inference, 0.0ms NMS per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/predict-cls/exp4\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}